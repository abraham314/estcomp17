---
title: "10-Tarea: bootstrap paramétrico" 

Author: "Abraham Nieto 51556" 

output: html_document
---
```{r}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE
  )
comma <- function(x) format(x, digits = 2, big.mark = ",")
options(digits=3)

library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
```


1. Sean $X_1,...,X_n \sim N(\mu, 1)$. Sea $\theta = e^{\mu}$, crea una base de 
datos usando $\mu=5$ que consista de $n=100$ observaciones.
```{r}
set.seed(92417) 
n<-100
x<-rnorm(n,5,1)
```

*Usa el método delta para estimar $\hat{se}$ y crea un intervalo del 95% de
confianza. Usa boostrap paramétrico para crear un intervalo del 95%. Usa 
bootstrap no paramétrico para crear un intervalo del 95%. Compara tus respuestas.
```{r}
# Paso 1: calcular mu_hat y sigma_hat
repBN<-function(){
  x_star<-sample(x,n,replace=TRUE) 
  exp(mean(x_star))
}

mu_hat<-mean(x)

repB<-function(){
  x_star<-rnorm(n,mu_hat,1) 
  exp(mean(x_star))
}

repsBN<-rerun(1000,repBN())%>%flatten_dbl()
repsB<-rerun(1000,repB())%>%flatten_dbl()
sd(repsBN)
sd(repsB)



dat<-data.frame(metodo=c(rep("BN",1000),rep("BP",1000),rep("delta",1000)),sims=c(repsBN,repsB,rnorm(1000,exp(mu_hat),sd(repsBN))))

#intervalo delta
ICd<-c(exp(mu_hat)-1.96*sd(repsBN),exp(mu_hat)+1.96*sd(repsBN))
ICd

#intervalo no parametrico
ICBN<-c(round(quantile(repsBN, prob = 0.025), 2),round(quantile(repsBN, prob = 0.975) , 2))
ICBN

#intervalo paametrico
ICB<-c(round(quantile(repsB, prob = 0.025), 2),round(quantile(repsB, prob = 0.975) , 2))
ICB

```


*Realiza un histograma de replicaciones bootstrap para cada método, estas son
estimaciones de la distribución de $\hat{\theta}$. El método delta también nos
da una aproximación a esta distribución: $Normal(\hat{\theta},\hat{se}^2)$. 
Comparalos con la verdadera distribución de $\hat{\theta}$ (que puedes obtener 
vía simulación). ¿Cuál es la aproximación más cercana a la verdadera 
distribución?

```{r}
n<-100
xn<-rnorm(n,5,1)
thetbbot<-function(){
  st<-sample(xn,n,replace=TRUE)
  exp(mean(st))
}
real<-rerun(1000,thetbbot())%>%flatten_dbl()
ggplot(data=NULL,aes(x=real))+geom_histogram(binwidth = 10)

ggplot(data=dat,aes(x=sims))+geom_histogram(binwidth = 10)+facet_wrap(~metodo)


```


Pista: $se(\hat{\mu}) = 1/\sqrt{n}$

2. La base de datos vancouver.csv contiene promedios de precipitación de 
mediciones (en mm) provenientes de Vancouver entre 1960 y 1994. 

```{r}
van<-read.csv('vancouver.csv')
head(van)
```

* Utiliza b-splines cúbicos para estudiar la relación entre el día y el 
promedio registrado. Deberás crear una variable numérica x que represente el día
y utiliza como nudos los extremos y 3 puntos interiores igualmente espaciados, 
es decir, tendrás 4 regiones. Grafica la curva estimada.

```{r}
library(Hmisc)
n<-nrow(van)
c<-c(1:nrow(van))
van$x<-c


toy_k <- van %>%
    mutate(int = cut2(x, g = 4)) %>%
    group_by(int) %>%
    mutate(media = mean(prec))

ggplot(toy_k, aes(x, prec)) +
  geom_point() +
  geom_smooth(method = "lm", aes(x, y = prec, group = int), color = "red", se = FALSE)


ggplot(van,aes(x,prec))+geom_point()

library(fda) # paquete con funciones útiles de splines

knots <- quantile(c)
knots
  # usamos la función create.bspline.basis para crear la base
  base <- create.bspline.basis(
      norder = 4, # polinomios cúbicos
      breaks = knots # nodos en los cuartiles de x
      )
  plot(base, lty = "solid")

```
```{r}
H <- eval.basis(c, base)
head(H)

beta_hat <- as.vector(solve(t(H) %*% H) %*% t(H) %*% toy_k$prec)
beta_hat


# creamos una función que calcula mu(x)
mu <- function(c, betas){
    as.numeric(betas %*% t(eval.basis(c, base)))
}

ggplot(toy_k, aes(x = x, y = prec)) +
    geom_point(alpha = 0.8) + 
    stat_function(fun = mu, args = list(betas = beta_hat), color = "blue") +
    labs(title = "B-splines")

```


* Crea bandas de errores estándar usando bootstrap paramético y suponiendo que 
los errores tienen una distribución normal.

Hacemos bootstrap parametrico dado que sabemos como se distribuyen los errores...

```{r}
mu_hat <- mu(toy_k$x, beta_hat)
sigma_hat <- sqrt(1 / n * sum((toy_k$prec - mu_hat) ^ 2))

# creamos las muestras bootstrap (paramétrico)
splinesBootP <- function(){
    toy_boot <- data.frame(x = toy_k$x, y = mu_hat + rnorm(n, 0, sigma_hat))
    H <- eval.basis(toy_boot$x, base)
    as.vector(solve(t(H) %*% H) %*% t(H) %*% toy_boot$y)
}

betas_p <- rerun(4000, splinesBootP()) %>% reduce(rbind)

splines_boot_p <- ggplot(toy_k, aes(x = x, y = prec)) 
for(i in 1:100){
    splines_boot_p <- splines_boot_p + 
        stat_function(fun = mu, args = list(betas = betas_p[i, ]), alpha = 0.1) 
}

splines_boot_p + geom_point(color = "red", alpha = 0.5) 

```
```{r}
# construimos los intervalos
x_grid <- seq(knots[1], knots[5], 0.03) # creamos un grid para evaluar mu(x)
H <- eval.basis(x_grid, base) # Evalúo la base en el rango
y <- betas_p %*% t(H) # calculo mu(x*)

betas_list <- split(betas_p, seq(nrow(betas_p)))
y <- purrr::map_df(betas_list, ~ data_frame(x = x_grid, mu = as.vector(. %*% t(H))))
limites <- y %>% 
  group_by(x) %>% 
  summarise(
    limite_inf = quantile(mu, probs = 0.025), 
    limite_sup = quantile(mu, probs = 0.975)
    )
  
ggplot(limites) + 
    geom_line(aes(x = x, y = limite_inf), color = "darkgray") +
    geom_line(aes(x = x, y = limite_sup), color = "darkgray") +
    geom_point(data = toy_k, aes(x = x, y = prec), color = "red", alpha = 0.5) + 
    stat_function(fun = mu, args = list(betas = beta_hat), color = "blue") +
    labs(x = "dias", y = "Prec")
```


